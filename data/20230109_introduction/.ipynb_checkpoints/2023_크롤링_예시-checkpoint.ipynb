{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07b2a527",
   "metadata": {},
   "source": [
    "### Seleninum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3feb2b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Using cached selenium-4.7.2-py3-none-any.whl (6.3 MB)\n",
      "Collecting trio~=0.17\n",
      "  Downloading trio-0.22.0-py3-none-any.whl (384 kB)\n",
      "     ------------------------------------- 384.9/384.9 kB 12.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\user\\anaconda3\\envs\\crawlling_2023\\lib\\site-packages (from selenium) (2022.12.7)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\users\\user\\anaconda3\\envs\\crawlling_2023\\lib\\site-packages (from selenium) (1.26.13)\n",
      "Collecting trio-websocket~=0.9\n",
      "  Using cached trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n",
      "Collecting sortedcontainers\n",
      "  Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: sniffio in c:\\users\\user\\anaconda3\\envs\\crawlling_2023\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Collecting async-generator>=1.9\n",
      "  Using cached async_generator-1.10-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\user\\anaconda3\\envs\\crawlling_2023\\lib\\site-packages (from trio~=0.17->selenium) (22.2.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\user\\anaconda3\\envs\\crawlling_2023\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Collecting outcome\n",
      "  Downloading outcome-1.2.0-py2.py3-none-any.whl (9.7 kB)\n",
      "Collecting exceptiongroup>=1.0.0rc9\n",
      "  Downloading exceptiongroup-1.1.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: idna in c:\\users\\user\\anaconda3\\envs\\crawlling_2023\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Collecting wsproto>=0.14\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Collecting PySocks!=1.5.7,<2.0,>=1.5.6\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: pycparser in c:\\users\\user\\anaconda3\\envs\\crawlling_2023\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Collecting h11<1,>=0.9.0\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "     ---------------------------------------- 58.3/58.3 kB ? eta 0:00:00\n",
      "Installing collected packages: sortedcontainers, PySocks, outcome, h11, exceptiongroup, async-generator, wsproto, trio, trio-websocket, selenium\n",
      "Successfully installed PySocks-1.7.1 async-generator-1.10 exceptiongroup-1.1.0 h11-0.14.0 outcome-1.2.0 selenium-4.7.2 sortedcontainers-2.4.0 trio-0.22.0 trio-websocket-0.9.2 wsproto-1.2.0\n"
     ]
    }
   ],
   "source": [
    "! pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66a97f37",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14260\\1812908593.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  browser = webdriver.Chrome(\"./chromedriver\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google 정보\n",
      "스토어\n",
      "Gmail이미지\n",
      "로그인\n",
      "대한민국\n",
      "광고\n",
      "비즈니스\n",
      "검색의 원리\n",
      "개인정보처리방침\n",
      "약관\n",
      "설정\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "browser = webdriver.Chrome(\"./chromedriver\")\n",
    "browser.get(\"http://www.google.com\")\n",
    "print(browser.find_element(By.XPATH, \"/html/body\").text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b29a10b",
   "metadata": {},
   "source": [
    "#### 네이버스포츠 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d31be0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라리가 OSEN 관심 확인 구단 4개.. 마르카 \"라리가 보물 이강인, 금액 문제 안돼\"\n",
      "배구 조선일보 감독도 김연경도 없이…흥국생명 4연승 질주\n",
      "스포츠 일반 한국일보 '중학생' 신지아, 여자 피겨 정상 등극…실수해도 흔들리지 않아\n",
      "배구 OSEN 자숙 끝내고 695일 만에 성공적 복귀, OK금융그룹 봄배구 이끄나\n",
      "테니스 뉴시스 조코비치, 새해 첫 대회 정상…3시간10분 혈투 끝 승리\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "#from selenium.webdriver.common.keys import Keys\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "browser = webdriver.Chrome()\n",
    "url=\"https://sports.news.naver.com/index.nhn\"\n",
    "browser.get(url)\n",
    "boxes = browser.find_elements(By.CSS_SELECTOR, \".today_item div.text_area\")\n",
    "\n",
    "#import time\n",
    "#time.sleep(3)\n",
    "for box in boxes:\n",
    "    # title = browser.find~~~~`\n",
    "    title = box.find_element(By.CSS_SELECTOR, \"strong.title\") #기사타이틀\n",
    "    newspaper = box.find_element(By.CSS_SELECTOR, \".information span\").text #신문사\n",
    "    sport = box.find_element(By.CSS_SELECTOR, \".information span:nth-child(2)\").text #스포츠 상위 주제\n",
    "    print(sport, newspaper, title.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3119dd4e",
   "metadata": {},
   "source": [
    "####  멜론 사이트 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3680fc89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\user\\anaconda3\\envs\\crawlling_2023\\lib\\site-packages (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\user\\anaconda3\\envs\\crawlling_2023\\lib\\site-packages (from beautifulsoup4) (2.3.2.post1)\n"
     ]
    }
   ],
   "source": [
    "! pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4fb14c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#실습: 멜론 사이트 접속하기 \n",
    "\n",
    "from selenium import webdriver\n",
    "#from selenium.webdriver.common.keys import Keys\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "url = 'http://www.melon.com/chart/index.htm'\n",
    "driver.get(url)     \n",
    "\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, 'html.parser')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56c8d523",
   "metadata": {},
   "outputs": [],
   "source": [
    "#반복문을 이용해 곡과 가수명을 song_data에 저장하기 \n",
    "song_data = []\n",
    "rank = 1\n",
    "\n",
    "songs = soup.select('table > tbody > tr')\n",
    "for song in songs:                                        \n",
    "    title = song.select('div.rank01 > span > a')[0].text\n",
    "    singer = song.select('div.rank02 > a')[0].text\n",
    "    song_data.append(['Melon', rank, title, singer])\n",
    "    rank = rank + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f93daa32",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>서비스</th>\n",
       "      <th>순위</th>\n",
       "      <th>타이틀</th>\n",
       "      <th>가수</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Melon</td>\n",
       "      <td>1</td>\n",
       "      <td>Ditto</td>\n",
       "      <td>NewJeans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Melon</td>\n",
       "      <td>2</td>\n",
       "      <td>OMG</td>\n",
       "      <td>NewJeans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Melon</td>\n",
       "      <td>3</td>\n",
       "      <td>Hype boy</td>\n",
       "      <td>NewJeans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Melon</td>\n",
       "      <td>4</td>\n",
       "      <td>사건의 지평선</td>\n",
       "      <td>윤하 (YOUNHA)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Melon</td>\n",
       "      <td>5</td>\n",
       "      <td>Candy</td>\n",
       "      <td>NCT DREAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Melon</td>\n",
       "      <td>96</td>\n",
       "      <td>아픈 나를</td>\n",
       "      <td>성시경</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Melon</td>\n",
       "      <td>97</td>\n",
       "      <td>Tangerine Love (Favorite)</td>\n",
       "      <td>NCT DREAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Melon</td>\n",
       "      <td>98</td>\n",
       "      <td>도깨비불 (Illusion)</td>\n",
       "      <td>aespa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Melon</td>\n",
       "      <td>99</td>\n",
       "      <td>가을꽃</td>\n",
       "      <td>김호중</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Melon</td>\n",
       "      <td>100</td>\n",
       "      <td>FOREVER 1</td>\n",
       "      <td>소녀시대 (GIRLS' GENERATION)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      서비스   순위                        타이틀                        가수\n",
       "0   Melon    1                      Ditto                  NewJeans\n",
       "1   Melon    2                        OMG                  NewJeans\n",
       "2   Melon    3                   Hype boy                  NewJeans\n",
       "3   Melon    4                    사건의 지평선               윤하 (YOUNHA)\n",
       "4   Melon    5                      Candy                 NCT DREAM\n",
       "..    ...  ...                        ...                       ...\n",
       "95  Melon   96                      아픈 나를                       성시경\n",
       "96  Melon   97  Tangerine Love (Favorite)                 NCT DREAM\n",
       "97  Melon   98            도깨비불 (Illusion)                     aespa\n",
       "98  Melon   99                        가을꽃                       김호중\n",
       "99  Melon  100                  FOREVER 1  소녀시대 (GIRLS' GENERATION)\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#song_data 리스트를 이용해 데이터프레임 만들기 \n",
    "import pandas as pd\n",
    "columns = ['서비스', '순위', '타이틀', '가수']\n",
    "pd_data = pd.DataFrame(song_data, columns = columns)\n",
    "pd_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a921ed44",
   "metadata": {},
   "source": [
    "#### 탄지로 크롤러"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be2858f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e02d43fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get('http://www.google.co.kr/imghp?hl=ko')\n",
    "elem = driver.find_element(By.NAME, \"q\")\n",
    "elem.send_keys(\"탄지로\")\n",
    "elem.send_keys(Keys.RETURN)   #enter 키 치는거 자동화임\n",
    "\n",
    "\n",
    "SCROLL_PAUSE_TIME = 1\n",
    "# Get scroll height\n",
    "last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "while True:\n",
    "    # Scroll down to bottom\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    # Wait to load page\n",
    "    time.sleep(SCROLL_PAUSE_TIME)\n",
    "    # Calculate new scroll height and compare with last scroll height\n",
    "    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    if new_height == last_height:\n",
    "        try:\n",
    "            driver.find_element_by_css_selector(\".mye4qd\").click()\n",
    "        except:\n",
    "            break\n",
    "    last_height = new_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2743bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crawlling_2023-ker",
   "language": "python",
   "name": "crawlling_2023"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
